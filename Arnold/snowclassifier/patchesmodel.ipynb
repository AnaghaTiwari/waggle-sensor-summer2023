{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import transforms, models, datasets\n",
    "from matplotlib.pyplot import imshow\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device =torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "root = \"./images/patches\"\n",
    "transformation = transforms.Compose([transforms.Resize((224,224)),\n",
    "                                     transforms.ToTensor()\n",
    "                                    ])\n",
    "data = datasets.ImageFolder(root = root, transform=transformation)\n",
    "train_set, test_set = torch.utils.data.random_split(data, [int(len(data) * 0.8), len(data) -int(len(data) * 0.8) ])\n",
    "\n",
    "#csvloader = torch.utils.data.DataLoader(data, batch_size = 1, shuffle = True)\n",
    "# snow, nosnow = [], []\n",
    "# for img, lbl in csvloader:\n",
    "#     if(lbl == 1):\n",
    "#         snow.append(img)\n",
    "# snow = torch.cat(snow, dim = 0)\n",
    "\n",
    "# train_snow, test_snow = torch.split(snow, [int(0.8*len(snow)), len(snow) - int(0.8*len(snow))])\n",
    "# print('data loaded')\n",
    "# for num,part in enumerate(torch.split(train_snow,10)):\n",
    "#     torch.save(part, f'train_patches_snow{num}.pt')\n",
    "# for num,part in enumerate(torch.split(test_snow,10)):\n",
    "#     torch.save(part, f'test_patches_snow{num}.pt')\n",
    "\n",
    "# for img, lbl in csvloader:\n",
    "#     if(lbl == 0):\n",
    "#         nosnow.append(img)\n",
    "# nosnow = torch.cat(nosnow, dim = 0)\n",
    "\n",
    "# train_nosnow, test_nosnow = torch.split(nosnow, [int(0.8*len(nosnow)), len(nosnow) - int(0.8*len(nosnow))])\n",
    "# print('data loaded')\n",
    "\n",
    "# for num,part in enumerate(torch.split(train_nosnow,10)):\n",
    "#     torch.save(part, f'train_patches_nosnow{num}.pt')\n",
    "# for num,part in enumerate(torch.split(test_nosnow,10)):\n",
    "#     torch.save(part, f'test_patches_nosnow{num}.pt')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformation = transforms.Compose([transforms.RandomPerspective(0.6, p=0.5),transforms.GaussianBlur(5)])\n",
    "\n",
    "# class riverdataset(torch.utils.data.Dataset):\n",
    "#     def __init__(self, snow_file, nosnow_file, transform = None):\n",
    "#         \"\"\"\n",
    "#         Arguments:\n",
    "#             snow_file (string): Path to the .pt file\n",
    "#             nosnow_file (string): Path to the .pt file\n",
    "#             noise (boolean): add guassian noise\n",
    "#         \"\"\"\n",
    "#         snow = torch.load(snow_file)\n",
    "#         nosnow = torch.load(nosnow_file)\n",
    "#         labels1 = torch.tensor([1 for i in range(len(snow))])\n",
    "#         labels0 = torch.tensor([0 for i in range(len(nosnow))])\n",
    "#         self.data = torch.cat([snow, nosnow], dim= 0)\n",
    "#         self.labels = torch.cat([labels1, labels0], dim = 0)\n",
    "        \n",
    "#         self.transform = transform\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.labels)\n",
    "    \n",
    "#     def __getitem__(self, idx):\n",
    "#         image = self.data[idx]\n",
    "#         if(self.transform):\n",
    "#             image = self.transform(image)\n",
    "#         return image, self.labels[idx]\n",
    "    \n",
    "\n",
    "# train_set = riverdataset(\"train_patches_snow.pt\", \"train_patches_nosnow.pt\", transformation)\n",
    "# test_set = riverdataset('test_patches_snow.pt', \"test_patches_nosnow.pt\", False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=2048, out_features=128, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=128, out_features=2, bias=True)\n",
       "    (3): Softmax(dim=1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create additional layers for snow classification\n",
    "model = models.resnet50(weights =models.ResNet50_Weights.IMAGENET1K_V2)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False   \n",
    "\n",
    "model.fc = torch.nn.Sequential(\n",
    "    torch.nn.Linear(2048, 128),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(128,2),\n",
    "    torch.nn.Softmax(dim= 1)\n",
    ")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameters\n",
    "\n",
    "lr = 0.0001\n",
    "batch_size = 256\n",
    "epochs =40\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.fc.parameters(), lr)\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size= batch_size, shuffle= True)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size= 1, shuffle= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_test_accuracy(model, dataloader,epoch, save_pic = False, criterion =torch.nn.CrossEntropyLoss()):\n",
    "      model.eval()\n",
    "      TP = 0\n",
    "      FP = 0\n",
    "      TN = 0\n",
    "      FN = 0\n",
    "      val_loss = 0\n",
    "      with torch.no_grad():\n",
    "            for num, (i, l) in enumerate(dataloader):\n",
    "                  if(save_pic):     \n",
    "                        plt.imsave(f\"image{num}.png\",i.squeeze(0).permute(1,2,0).numpy() )\n",
    "                 \n",
    "                  if(l == torch.tensor([0])):\n",
    "                        l = torch.tensor([1, 0])\n",
    "                  else:\n",
    "                        l = torch.tensor([0, 1])\n",
    "                  l = l.reshape([1,2])\n",
    "                  i,l = i.to(device), l.to(device).float()\n",
    "                  t_out = model(i)\n",
    "                  \n",
    "                  \n",
    "                  val_loss+= criterion(t_out, l).item()\n",
    "                  predicted = np.argmax(t_out.cpu().numpy(), axis = 1)\n",
    "                  true_label = np.argmax(l.cpu().numpy(), axis =1)\n",
    "                 \n",
    "                  if(predicted == 1 and true_label == 1):\n",
    "                        TP +=1\n",
    "                  elif(predicted == 0 and true_label == 0):\n",
    "                        TN +=1\n",
    "                  if(predicted == 1 and true_label == 0):\n",
    "                        FP +=1\n",
    "                        #plt.imsave(f\"imageFP{num}.png\",i.cpu().squeeze(0).permute(1,2,0).numpy() )\n",
    "                  elif(predicted == 0 and true_label == 1):\n",
    "                        FN +=1\n",
    "                        #plt.imsave(f\"imageFN{num}.png\",i.cpu().squeeze(0).permute(1,2,0).numpy() )\n",
    "            try:\n",
    "                  precision = TP/(TP + FP)\n",
    "            except:\n",
    "                  precision = 0\n",
    "            try:\n",
    "                  recall = TP/(TP + FN)\n",
    "            except:\n",
    "                  recall = 0\n",
    "            stats = dict(\n",
    "                  epoch = epoch,\n",
    "                  accuracy = (TN+TP) /(TP+TN+FP+FN),\n",
    "                  precision = precision,\n",
    "                  recall = recall,\n",
    "                  loss = val_loss/(TP+FP+TN+FN)\n",
    "            \n",
    "            )\n",
    "            # print(f'True positives: {TP}')\n",
    "            # print(f'True negatives: {TN}')\n",
    "            # print(f'False positives: {FP}')\n",
    "            \n",
    "            # print(f'False negatives: {FN}')\n",
    "            return stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "step : 10/178\n",
      "step : 20/178\n",
      "step : 30/178\n",
      "step : 40/178\n",
      "step : 50/178\n",
      "step : 60/178\n",
      "step : 70/178\n",
      "step : 80/178\n",
      "step : 90/178\n",
      "step : 100/178\n",
      "step : 110/178\n",
      "step : 120/178\n",
      "step : 130/178\n",
      "step : 140/178\n",
      "step : 150/178\n",
      "step : 160/178\n",
      "step : 170/178\n",
      "testing\n",
      "{'epoch': 1, 'accuracy': 0.8807307219392236, 'precision': 0.8818459328425211, 'recall': 0.875245054357512, 'loss': 0.4496864829334793, 'training_loss': [0.5187478770365875]}\n",
      "1\n",
      "step : 10/178\n",
      "step : 20/178\n",
      "step : 30/178\n",
      "step : 40/178\n",
      "step : 50/178\n",
      "step : 60/178\n",
      "step : 70/178\n",
      "step : 80/178\n",
      "step : 90/178\n",
      "step : 100/178\n",
      "step : 110/178\n",
      "step : 120/178\n",
      "step : 130/178\n",
      "step : 140/178\n",
      "step : 150/178\n",
      "step : 160/178\n",
      "step : 170/178\n",
      "2\n",
      "step : 10/178\n",
      "step : 20/178\n",
      "step : 30/178\n",
      "step : 40/178\n",
      "step : 50/178\n",
      "step : 60/178\n",
      "step : 70/178\n",
      "step : 80/178\n",
      "step : 90/178\n",
      "step : 100/178\n",
      "step : 110/178\n",
      "step : 120/178\n",
      "step : 130/178\n",
      "step : 140/178\n",
      "step : 150/178\n",
      "step : 160/178\n",
      "step : 170/178\n",
      "testing\n",
      "{'epoch': 3, 'accuracy': 0.91392938696645, 'precision': 0.9386247395340026, 'recall': 0.883086793797897, 'loss': 0.40574046275788656, 'training_loss': [0.5187478770365875, 0.4356907403536057, 0.4146640185224876]}\n",
      "3\n",
      "step : 10/178\n",
      "step : 20/178\n",
      "step : 30/178\n",
      "step : 40/178\n",
      "step : 50/178\n",
      "step : 60/178\n",
      "step : 70/178\n",
      "step : 80/178\n",
      "step : 90/178\n",
      "step : 100/178\n",
      "step : 110/178\n",
      "step : 120/178\n",
      "step : 130/178\n",
      "step : 140/178\n",
      "step : 150/178\n",
      "step : 160/178\n",
      "step : 170/178\n",
      "4\n",
      "step : 10/178\n",
      "step : 20/178\n",
      "step : 30/178\n",
      "step : 40/178\n",
      "step : 50/178\n",
      "step : 60/178\n",
      "step : 70/178\n",
      "step : 80/178\n",
      "step : 90/178\n",
      "step : 100/178\n",
      "step : 110/178\n",
      "step : 120/178\n",
      "step : 130/178\n",
      "step : 140/178\n",
      "step : 150/178\n",
      "step : 160/178\n",
      "step : 170/178\n",
      "testing\n",
      "{'epoch': 5, 'accuracy': 0.9236782012998419, 'precision': 0.9446736684171043, 'recall': 0.8977009445731599, 'loss': 0.3924708704438127, 'training_loss': [0.5187478770365875, 0.4356907403536057, 0.4146640185224876, 0.4052956003821298, 0.3980302524365736]}\n",
      "5\n",
      "step : 10/178\n",
      "step : 20/178\n",
      "step : 30/178\n",
      "step : 40/178\n",
      "step : 50/178\n",
      "step : 60/178\n",
      "step : 70/178\n",
      "step : 80/178\n",
      "step : 90/178\n",
      "step : 100/178\n",
      "step : 110/178\n",
      "step : 120/178\n",
      "step : 130/178\n",
      "step : 140/178\n",
      "step : 150/178\n",
      "step : 160/178\n",
      "step : 170/178\n",
      "6\n",
      "step : 10/178\n",
      "step : 20/178\n",
      "step : 30/178\n",
      "step : 40/178\n",
      "step : 50/178\n",
      "step : 60/178\n",
      "step : 70/178\n",
      "step : 80/178\n",
      "step : 90/178\n",
      "step : 100/178\n",
      "step : 110/178\n",
      "step : 120/178\n",
      "step : 130/178\n",
      "step : 140/178\n",
      "step : 150/178\n",
      "step : 160/178\n",
      "step : 170/178\n",
      "testing\n",
      "{'epoch': 7, 'accuracy': 0.9304408923239066, 'precision': 0.9294243450365354, 'recall': 0.9294243450365354, 'loss': 0.38631849047977684, 'training_loss': [0.5187478770365875, 0.4356907403536057, 0.4146640185224876, 0.4052956003821298, 0.3980302524365736, 0.3928755649020163, 0.38993493057368844]}\n",
      "7\n",
      "step : 10/178\n",
      "step : 20/178\n",
      "step : 30/178\n",
      "step : 40/178\n",
      "step : 50/178\n",
      "step : 60/178\n",
      "step : 70/178\n",
      "step : 80/178\n",
      "step : 90/178\n",
      "step : 100/178\n",
      "step : 110/178\n",
      "step : 120/178\n",
      "step : 130/178\n",
      "step : 140/178\n",
      "step : 150/178\n",
      "step : 160/178\n",
      "step : 170/178\n",
      "8\n",
      "step : 10/178\n",
      "step : 20/178\n",
      "step : 30/178\n",
      "step : 40/178\n",
      "step : 50/178\n",
      "step : 60/178\n",
      "step : 70/178\n",
      "step : 80/178\n",
      "step : 90/178\n",
      "step : 100/178\n",
      "step : 110/178\n",
      "step : 120/178\n",
      "step : 130/178\n",
      "step : 140/178\n",
      "step : 150/178\n",
      "step : 160/178\n",
      "step : 170/178\n",
      "testing\n",
      "{'epoch': 9, 'accuracy': 0.9309678552608467, 'precision': 0.9387161302054919, 'recall': 0.9199786134378899, 'loss': 0.3831650276066192, 'training_loss': [0.5187478770365875, 0.4356907403536057, 0.4146640185224876, 0.4052956003821298, 0.3980302524365736, 0.3928755649020163, 0.38993493057368844, 0.3870877583375138, 0.38447398282168954]}\n",
      "9\n",
      "step : 10/178\n",
      "step : 20/178\n",
      "step : 30/178\n",
      "step : 40/178\n",
      "step : 50/178\n",
      "step : 60/178\n",
      "step : 70/178\n",
      "step : 80/178\n",
      "step : 90/178\n",
      "step : 100/178\n",
      "step : 110/178\n",
      "step : 120/178\n",
      "step : 130/178\n",
      "step : 140/178\n",
      "step : 150/178\n",
      "step : 160/178\n",
      "step : 170/178\n",
      "10\n",
      "step : 10/178\n",
      "step : 20/178\n",
      "step : 30/178\n",
      "step : 40/178\n",
      "step : 50/178\n",
      "step : 60/178\n",
      "step : 70/178\n",
      "step : 80/178\n",
      "step : 90/178\n",
      "step : 100/178\n",
      "step : 110/178\n",
      "step : 120/178\n",
      "step : 130/178\n",
      "step : 140/178\n",
      "step : 150/178\n",
      "step : 160/178\n",
      "step : 170/178\n",
      "testing\n",
      "{'epoch': 11, 'accuracy': 0.9349200772878974, 'precision': 0.9334282662869349, 'recall': 0.9345927642131527, 'loss': 0.3803993666630605, 'training_loss': [0.5187478770365875, 0.4356907403536057, 0.4146640185224876, 0.4052956003821298, 0.3980302524365736, 0.3928755649020163, 0.38993493057368844, 0.3870877583375138, 0.38447398282168954, 0.3833862156345603, 0.38130912385629806]}\n",
      "11\n",
      "step : 10/178\n",
      "step : 20/178\n",
      "step : 30/178\n",
      "step : 40/178\n",
      "step : 50/178\n",
      "step : 60/178\n",
      "step : 70/178\n",
      "step : 80/178\n",
      "step : 90/178\n",
      "step : 100/178\n",
      "step : 110/178\n",
      "step : 120/178\n",
      "step : 130/178\n",
      "step : 140/178\n",
      "step : 150/178\n",
      "step : 160/178\n",
      "step : 170/178\n",
      "12\n",
      "step : 10/178\n",
      "step : 20/178\n",
      "step : 30/178\n",
      "step : 40/178\n",
      "step : 50/178\n",
      "step : 60/178\n",
      "step : 70/178\n",
      "step : 80/178\n",
      "step : 90/178\n",
      "step : 100/178\n",
      "step : 110/178\n",
      "step : 120/178\n",
      "step : 130/178\n",
      "step : 140/178\n",
      "step : 150/178\n",
      "step : 160/178\n",
      "step : 170/178\n",
      "testing\n",
      "{'epoch': 13, 'accuracy': 0.9357105216933076, 'precision': 0.9327656554905092, 'recall': 0.9370878631260025, 'loss': 0.3784778343967409, 'training_loss': [0.5187478770365875, 0.4356907403536057, 0.4146640185224876, 0.4052956003821298, 0.3980302524365736, 0.3928755649020163, 0.38993493057368844, 0.3870877583375138, 0.38447398282168954, 0.3833862156345603, 0.38130912385629806, 0.38010979251245436, 0.3782715539583999]}\n",
      "13\n",
      "step : 10/178\n",
      "step : 20/178\n",
      "step : 30/178\n",
      "step : 40/178\n",
      "step : 50/178\n",
      "step : 60/178\n",
      "step : 70/178\n",
      "step : 80/178\n",
      "step : 90/178\n",
      "step : 100/178\n",
      "step : 110/178\n",
      "step : 120/178\n",
      "step : 130/178\n",
      "step : 140/178\n",
      "step : 150/178\n",
      "step : 160/178\n",
      "step : 170/178\n",
      "14\n",
      "step : 10/178\n",
      "step : 20/178\n",
      "step : 30/178\n",
      "step : 40/178\n",
      "step : 50/178\n",
      "step : 60/178\n",
      "step : 70/178\n",
      "step : 80/178\n",
      "step : 90/178\n",
      "step : 100/178\n",
      "step : 110/178\n",
      "step : 120/178\n",
      "step : 130/178\n",
      "step : 140/178\n",
      "step : 150/178\n",
      "step : 160/178\n",
      "step : 170/178\n",
      "testing\n",
      "{'epoch': 15, 'accuracy': 0.9374670648164413, 'precision': 0.9430276722734672, 'recall': 0.9292461236856175, 'loss': 0.37723219603033115, 'training_loss': [0.5187478770365875, 0.4356907403536057, 0.4146640185224876, 0.4052956003821298, 0.3980302524365736, 0.3928755649020163, 0.38993493057368844, 0.3870877583375138, 0.38447398282168954, 0.3833862156345603, 0.38130912385629806, 0.38010979251245436, 0.3782715539583999, 0.37800059743811576, 0.3770186822401004]}\n",
      "15\n",
      "step : 10/178\n",
      "step : 20/178\n",
      "step : 30/178\n",
      "step : 40/178\n",
      "step : 50/178\n",
      "step : 60/178\n",
      "step : 70/178\n",
      "step : 80/178\n",
      "step : 90/178\n",
      "step : 100/178\n",
      "step : 110/178\n",
      "step : 120/178\n",
      "step : 130/178\n",
      "step : 140/178\n",
      "step : 150/178\n",
      "step : 160/178\n",
      "step : 170/178\n",
      "16\n",
      "step : 10/178\n",
      "step : 20/178\n",
      "step : 30/178\n",
      "step : 40/178\n",
      "step : 50/178\n",
      "step : 60/178\n",
      "step : 70/178\n",
      "step : 80/178\n",
      "step : 90/178\n",
      "step : 100/178\n",
      "step : 110/178\n",
      "step : 120/178\n",
      "step : 130/178\n",
      "step : 140/178\n",
      "step : 150/178\n",
      "step : 160/178\n",
      "step : 170/178\n",
      "testing\n",
      "{'epoch': 17, 'accuracy': 0.935886176005621, 'precision': 0.9343299519487454, 'recall': 0.9356620923186598, 'loss': 0.37658351411116725, 'training_loss': [0.5187478770365875, 0.4356907403536057, 0.4146640185224876, 0.4052956003821298, 0.3980302524365736, 0.3928755649020163, 0.38993493057368844, 0.3870877583375138, 0.38447398282168954, 0.3833862156345603, 0.38130912385629806, 0.38010979251245436, 0.3782715539583999, 0.37800059743811576, 0.3770186822401004, 0.375948025102026, 0.37508292479461497]}\n",
      "17\n",
      "step : 10/178\n",
      "step : 20/178\n",
      "step : 30/178\n",
      "step : 40/178\n",
      "step : 50/178\n",
      "step : 60/178\n",
      "step : 70/178\n",
      "step : 80/178\n",
      "step : 90/178\n",
      "step : 100/178\n",
      "step : 110/178\n",
      "step : 120/178\n",
      "step : 130/178\n",
      "step : 140/178\n",
      "step : 150/178\n",
      "step : 160/178\n",
      "step : 170/178\n",
      "18\n",
      "step : 10/178\n",
      "step : 20/178\n",
      "step : 30/178\n",
      "step : 40/178\n",
      "step : 50/178\n",
      "step : 60/178\n",
      "step : 70/178\n",
      "step : 80/178\n",
      "step : 90/178\n",
      "step : 100/178\n",
      "step : 110/178\n",
      "step : 120/178\n",
      "step : 130/178\n",
      "step : 140/178\n",
      "step : 150/178\n",
      "step : 160/178\n",
      "step : 170/178\n",
      "testing\n",
      "{'epoch': 19, 'accuracy': 0.9351835587563675, 'precision': 0.9290368022539179, 'recall': 0.9402958474425236, 'loss': 0.3768641053321553, 'training_loss': [0.5187478770365875, 0.4356907403536057, 0.4146640185224876, 0.4052956003821298, 0.3980302524365736, 0.3928755649020163, 0.38993493057368844, 0.3870877583375138, 0.38447398282168954, 0.3833862156345603, 0.38130912385629806, 0.38010979251245436, 0.3782715539583999, 0.37800059743811576, 0.3770186822401004, 0.375948025102026, 0.37508292479461497, 0.37474510693148283, 0.373587437057763]}\n",
      "19\n",
      "step : 10/178\n",
      "step : 20/178\n",
      "step : 30/178\n",
      "step : 40/178\n",
      "step : 50/178\n",
      "step : 60/178\n",
      "step : 70/178\n",
      "step : 80/178\n",
      "step : 90/178\n",
      "step : 100/178\n",
      "step : 110/178\n",
      "step : 120/178\n",
      "step : 130/178\n",
      "step : 140/178\n",
      "step : 150/178\n",
      "step : 160/178\n",
      "step : 170/178\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#training loop\n",
    "running_loss = 0 \n",
    "train_loss, test_loss = [],[]\n",
    "# model = torch.load(\"model.pth\")\n",
    "model.train()\n",
    "verbose = 10\n",
    "steps = 0\n",
    "\n",
    "for epoch in range(0, epochs):\n",
    "    print(epoch)\n",
    "    for images,labels in train_loader:\n",
    "        steps +=1\n",
    "        if(steps %10 == 0):\n",
    "            print(f'step : {steps}/{len(train_loader)}')\n",
    "        labels = torch.nn.functional.one_hot(labels)\n",
    "        images,labels = images.to(device), labels.to(device).float()\n",
    "        optimizer.zero_grad()\n",
    "        out = model(images)\n",
    "        loss = criterion(out, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    steps  = 0 \n",
    "        \n",
    "    val_loss = 0\n",
    "    num_correct = 0\n",
    "    model.eval()\n",
    "    train_loss.append(running_loss/len(train_loader))\n",
    "    if(epoch % 2 == 0):\n",
    "        with torch.no_grad():\n",
    "            print('testing')\n",
    "            stats = calc_test_accuracy(model, test_loader, epoch+1)\n",
    "            \n",
    "            test_loss.append(stats[\"loss\"])\n",
    "            stats[\"training_loss\"] = train_loss\n",
    "            torch.save(stats, f\"stats-{epoch+1}.pt\")\n",
    "            print(stats)\n",
    "    running_loss= 0\n",
    "    model.train()\n",
    "    torch.save(model, 'model.pth')\n",
    "    \n",
    "  \n",
    "\n",
    "\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('model.pth')\n",
    "stats = calc_test_accuracy(model, test_loader, epoch+1)\n",
    "stats[\"training_loss\"] = train_loss\n",
    "torch.save(stats, f\"stats-{epoch+1}.pt\")\n",
    "print(stats)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Plot the data\n",
    "ax.plot(train_loss, marker='o', linestyle='-', color='b')\n",
    "\n",
    "# Customize the plot\n",
    "ax.set_title('Snow ResNet50 Training Loss')\n",
    "ax.set_xlabel('X-axis')\n",
    "ax.set_ylabel('Y-axis')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Plot the data\n",
    "ax.plot(test_loss,marker='o', linestyle='-', color='b')\n",
    "\n",
    "# Customize the plot\n",
    "ax.set_title('Snow classifier ResNet50 Test Loss')\n",
    "ax.set_xlabel('X-axis')\n",
    "ax.set_ylabel('Y-axis')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies = []\n",
    "fig, ax = plt.subplots()\n",
    "for i in range(1,21):\n",
    "    accuracies.append(torch.load(f'stats-{i}.pt')['accuracy'])\n",
    "# Plot the data\n",
    "print(accuracies)\n",
    "ax.plot(accuracies,marker='o', linestyle='-', color='b')\n",
    "\n",
    "# Customize the plot\n",
    "ax.set_title('Snow Classifier ResNet50 Accuracy')\n",
    "ax.set_xlabel('X-axis')\n",
    "ax.set_ylabel('Y-axis')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sage",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
