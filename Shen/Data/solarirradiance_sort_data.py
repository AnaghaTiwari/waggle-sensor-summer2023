# -*- coding: utf-8 -*-
"""SolarIrradiance_Sort_Data.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/15RKOI-l-LprR4SpPdXsR-AVBk9A20ADg
"""
from pandas.io.formats.format import DataFrameFormatter
import csv
import sage_data_client
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
from datetime import datetime
from datetime import timedelta
import os
from PIL import Image
from io import BytesIO
import requests
from urllib.parse import urlparse














#Using pandas to preprocess
solar_rad_file = "Solar_Irradiance.csv"

#load in columns
#Data being read is only during the Summer Season



raw_csv_data = pd.read_csv(solar_rad_file)



df=raw_csv_data.copy()


##Remove the times when the sun is not out


def remove_dark_data(dataframe):
  for index, row in dataframe.iterrows():
    time = int(row['T_LST'][0:2] + row['T_LST'][3:5])
    if time < 600 or time > 2000:
      dataframe.drop(index, inplace=True)


remove_dark_data(df)



#Remove excess columns

def remove_columns(dataframe):
  for column_name, column_data in dataframe.items():
    if (column_name != 'T_LST' and column_name != 'JDA' and column_name != 'radW/m2'):
      dataframe.drop(column_name, axis=1, inplace= True)

remove_columns(df)


#Make sure the indices are rest properly


df.reset_index(drop = True, inplace=True)









def find_max(dataframe):
  max = -99999
  for index, row in dataframe.iterrows():
      if row['radW/m2'] > max:
        max = row['radW/m2']
  return max



def find_min(dataframe):
  min = 99999
  for index, row in dataframe.iterrows():
      if row['radW/m2'] < min:
        min = row['radW/m2']
  return min



def find_mean(dataframe):
  total = 0
  for index, row in dataframe.iterrows():
      total += row['radW/m2']
  return total/len(dataframe)



#maximum
max_solar_rad = find_max(df)

#minimum
min_solar_rad = find_min(df)

#range
range2 = max_solar_rad - min_solar_rad
print(f"The Solar Irradiances range between {max_solar_rad} and {min_solar_rad}, resulting in a range of {range2}")

#mean
mean = find_mean(df)
print(f"The average Solar Irradiance over the course of the summer: {mean}")




#convert the times to Decimal values to plot the graph in a logical manner
Day_Times_Combo = []
for index, row in df.iterrows():
    time = int(row['T_LST'][0:2] + row['T_LST'][3:5])
    real_time = float(time/2400)
    day = row['JDA']
    combo = day + real_time
    Day_Times_Combo.append(combo)


## Plot of radiations over the whole summer
## There is a whole in Day 205 because no Data was collected
def plot():

  x_data = Day_Times_Combo
  y_data = []
  for index, row in df.iterrows():
      y_data.append(row['radW/m2'])
  x = np.array(x_data)
  y= np.array(y_data)


  plt.plot(x, y, 'o', color='black', markersize = 2);

##Uncomment to Show Plot
plot()

#To see the Data
print(df)

###Images

#1. Remove the data that are earlier than 7AM and later than 7PM  :: Done

#2. Iterate through the list and calculate whichever values are closest to the each 15 minute mark :: Done

#3. Do this for Data from June, July, and August, and Combine the overall data to match the Solar Irradiance :: Done






##Remove all the images that were taken before 7AM or after 7PM

def remove_dark_data_im(dataframe):
    # Create a new series with the time as a numerical value
    time = dataframe['timestamp'].apply(lambda x: 100 * x.time().hour + x.time().minute)
    mask = (time >= 1100) | (time <= 100)
    dataframe = dataframe[mask]
    return dataframe




##Choose the images for each 15 minute interval

def choose_image_interval(dataframe):
  # Ensure that 'timestamp' is of type datetime
  dataframe2 = dataframe.copy()
  dataframe2['timestamp'] = pd.to_datetime(dataframe2['timestamp'])
  dataframe2 = dataframe2.set_index('timestamp')
  resampled_df = dataframe2.resample('15min').first()
  resampled_df = resampled_df.reset_index()
  return resampled_df





##Clean out the values that were being added from the every 15min interval func.
def clean_nones(dataframe):
  for index, row in dataframe.iterrows():
    if row['meta.job'] != 'sage':
      dataframe.drop(index, inplace= True)









##################

#June


#Load In all Data for Images in June

df_im_june = sage_data_client.query(
    start="2022-06-01T05:00:00.000Z",
    end="2022-07-01T05:00:00.000Z",
    filter={
        "vsn": "W039",
        "task": "imagesampler-top"
    }
)




## Clean the data using functions on month of June
cleaned_df_im_june = choose_image_interval(remove_dark_data_im(df_im_june))
clean_nones(cleaned_df_im_june)



#### Test whether the data was cleaned, June

#for index, row in cleaned_df_im_june.iterrows():
  #print(row['timestamp'])

####






##################

#July



#Load In all Data for Images in July

df_im_july = sage_data_client.query(
    start="2022-07-01T05:00:00.000Z",
    end="2022-07-31T05:00:00.000Z",
    filter={
        "vsn": "W039",
        "task": "imagesampler-top"
    }
)


cleaned_df_im_july = choose_image_interval(remove_dark_data_im(df_im_july))
clean_nones(cleaned_df_im_july)

for index, row in cleaned_df_im_july.iterrows():
  converted_date = (datetime.date(row['timestamp']))
  if converted_date.day == 23:
    cleaned_df_im_july.drop(index, inplace= True)




####

#Test whether the data was cleaned, July



#for index, row in cleaned_df_im_july.iterrows():
  #print(row['timestamp'])



####


##################

#August



#Load in all Image Data for August
df_im_aug = sage_data_client.query(
    start="2022-08-01T05:00:00.000Z",
    end="2022-08-31T05:00:00.000Z",
    filter={
        "vsn": "W039",
        "task": "imagesampler-top"
    }
)

cleaned_df_im_aug = choose_image_interval(remove_dark_data_im(df_im_aug))
clean_nones(cleaned_df_im_aug)

#### Test whether the data was cleaned, August

#for index, row in cleaned_df_im_aug.iterrows():
  #print(row['timestamp'])

####


##################



#Combine all three data frames

dataframes = [cleaned_df_im_june, cleaned_df_im_july, cleaned_df_im_aug]

all_cleaned_df_im = pd.concat(dataframes)

all_cleaned_df_im.reset_index(drop = True, inplace= True)
print(all_cleaned_df_im)


###

#Test Date Order


#for index, row in all_cleaned_df_im.iterrows():
  #print(row['timestamp'])



###





##################

##Final cleaning of the dataframes

all_cleaned_df_im = pd.concat(dataframes)
all_cleaned_df_im.reset_index(drop = True, inplace= True)


all_cleaned_df_im.drop(38, inplace= True)
all_cleaned_df_im.reset_index(drop = True, inplace= True)
all_cleaned_df_im.drop(268, inplace= True)
all_cleaned_df_im.reset_index(drop = True, inplace= True)
all_cleaned_df_im.drop(290, inplace= True)
all_cleaned_df_im.reset_index(drop = True, inplace= True)
all_cleaned_df_im.drop(329, inplace= True)
all_cleaned_df_im.reset_index(drop = True, inplace= True)
all_cleaned_df_im.drop(1086, inplace= True)
all_cleaned_df_im.reset_index(drop = True, inplace= True)
all_cleaned_df_im.drop(1086, inplace= True)
all_cleaned_df_im.reset_index(drop = True, inplace= True)
all_cleaned_df_im.drop(1086, inplace= True)
all_cleaned_df_im.reset_index(drop = True, inplace= True)
all_cleaned_df_im.drop(1086, inplace= True)
all_cleaned_df_im.reset_index(drop = True, inplace= True)
all_cleaned_df_im.drop(1162, inplace= True)
all_cleaned_df_im.reset_index(drop = True, inplace= True)
all_cleaned_df_im.drop(1162, inplace= True)
all_cleaned_df_im.reset_index(drop = True, inplace= True)
all_cleaned_df_im.drop(1162, inplace= True)
all_cleaned_df_im.reset_index(drop = True, inplace= True)
all_cleaned_df_im.drop(1162, inplace= True)
all_cleaned_df_im.reset_index(drop = True, inplace= True)
all_cleaned_df_im.drop(1162, inplace= True)
all_cleaned_df_im.reset_index(drop = True, inplace= True)
all_cleaned_df_im.drop(2281, inplace= True)
all_cleaned_df_im.reset_index(drop = True, inplace= True)
all_cleaned_df_im.drop(2649, inplace= True)
all_cleaned_df_im.reset_index(drop = True, inplace= True)










##Algorithm to identify differences in dates betweeen the two dataframe,
##To ensure each image is properly matching up to the correct solar irradiation measurement


x= 4000


while x < 4301:
  initial_image_datetime = all_cleaned_df_im.at[x,'timestamp'] - timedelta(hours=5)
  data_time = datetime.strptime((df.at[x, 'T_LST']), '%H:%M').time()
  image_time = datetime.time(initial_image_datetime)
  print("This is the image date: ")
  print(initial_image_datetime)
  print("\n")
  print("This is the data date: ")
  print(data_time)
  print("\n")
  if image_time != data_time:
    print(x)
    break
  x+=1

#Display the Final Cleaned Image Data


#for index,row in all_cleaned_df_im.iterrows():
  #print(row['value'])


print(all_cleaned_df_im)

##Sorting the images and Data into Classes




#1 Remove unecessary data in both data sets to make sorting easier


for column_name, column_data in all_cleaned_df_im.items():
  if (column_name != 'value'):
    all_cleaned_df_im.drop(column_name, axis=1, inplace= True)

#print(all_cleaned_df_im)


for column_name, column_data in df.items():
  if (column_name != 'radW/m2'):
    df.drop(column_name, axis=1, inplace= True)

#print(df)




#2 Combine both data sets
completed_df = pd.concat([all_cleaned_df_im, df], axis=1)

#print(completed_df)




#3 Remove negative values from the data set
for index, row in completed_df.iterrows():
  irradiance = row['radW/m2']
  if not(irradiance >= 0) :
    completed_df.drop(index, inplace= True)

completed_df.reset_index(drop = True, inplace= True)


#4 Remove values greater than 1000
for index, row in completed_df.iterrows():
  irradiance = row['radW/m2']
  if irradiance > 1000:
    completed_df.drop(index, inplace= True)


completed_df.reset_index(drop = True, inplace= True)

print(completed_df)



#count = 0
#for index, row in completed_df.iterrows():
  #if row['radW/m2'] > 1000:
    #print(row['radW/m2'])
    #count+=1
#print(count)









#4 Put the images into classes through Google drive




bins = list(range(0, 1100, 100))  # Bins from 0-1000 by 100


labels = [f'{i}-{i+100}' for i in bins[:-1]]  # creates labels ['0-100', '100-200', ..., '900-1000']

#print(labels)


irradiance = 'radW/m2'
image_url = 'value'


##Make a new column in the Data frame called class, that classifies each image/solarIrradiance value

completed_df['class'] = pd.cut(completed_df[irradiance], bins=bins, labels=labels, include_lowest=True)





###Store the images

image_dir = '/Users/alexshen/desktop/BaseDir'

for index, row in completed_df.iterrows():

  class_dir = os.path.join(image_dir, row['class'])
  os.makedirs(class_dir, exist_ok=True)

  parsed = urlparse(row[image_url])

  image_name = os.path.basename(parsed.path)

  destination = os.path.join(class_dir, image_name)

  #print(destination)


  response = requests.get(row[image_url], stream=True)

  if response.status_code == 200:
    with open(destination, 'wb') as out_file:
      out_file.write(response.content)

  del response



#print(completed_df)