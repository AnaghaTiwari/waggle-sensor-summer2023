{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dense,Flatten,Conv2D,Activation,Dropout\n",
    "from keras import backend as K\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.models import load_model\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import EarlyStopping,ModelCheckpoint\n",
    "from keras.layers import MaxPool2D\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 22273 images belonging to 3 classes.\n",
      "Found 5598 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "trdata = ImageDataGenerator()\n",
    "traindata = trdata.flow_from_directory(directory='/home/jszumny/Documents/copy of smoke data/hpwren/modeldata/training/',target_size=(224,224))\n",
    "tsdata = ImageDataGenerator()\n",
    "testdata = tsdata.flow_from_directory(directory='/home/jszumny/Documents/copy of smoke data/hpwren/modeldata/testing/', target_size=(224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_52 (Conv2D)          (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " conv2d_53 (Conv2D)          (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " max_pooling2d_16 (MaxPoolin  (None, 112, 112, 64)     0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_54 (Conv2D)          (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " conv2d_55 (Conv2D)          (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " max_pooling2d_17 (MaxPoolin  (None, 56, 56, 128)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_56 (Conv2D)          (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " conv2d_57 (Conv2D)          (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " conv2d_58 (Conv2D)          (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " max_pooling2d_18 (MaxPoolin  (None, 28, 28, 256)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_59 (Conv2D)          (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " conv2d_60 (Conv2D)          (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " conv2d_61 (Conv2D)          (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " max_pooling2d_19 (MaxPoolin  (None, 14, 14, 512)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_62 (Conv2D)          (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " conv2d_63 (Conv2D)          (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " conv2d_64 (Conv2D)          (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " vgg16 (MaxPooling2D)        (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " fc1 (Dense)                 (None, 256)               6422784   \n",
      "                                                                 \n",
      " fc2 (Dense)                 (None, 128)               32896     \n",
      "                                                                 \n",
      " output (Dense)              (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21,170,497\n",
      "Trainable params: 21,170,497\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def VGG16():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(input_shape=(224,224,3),filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
    "    model.add(Conv2D(filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
    "    model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "    model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "    model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "    model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "    model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "    model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "    model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "    model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "    model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "    model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "    model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "    model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "    model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "    model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "    model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "    model.add(MaxPool2D(pool_size=(2,2),strides=(2,2),name='vgg16'))\n",
    "    model.add(Flatten(name='flatten'))\n",
    "    model.add(Dense(256, activation='relu', name='fc1'))\n",
    "    model.add(Dense(128, activation='relu', name='fc2'))\n",
    "    model.add(Dense(1, activation='sigmoid', name='output'))\n",
    "    return model\n",
    "\n",
    "model = VGG16()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "Vgg16 = Model(inputs=model.input, outputs=model.get_layer('vgg16').output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "Vgg16.load_weights(\"/home/jszumny/Documents/copy of smoke data/hpwren/modeldata/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in Vgg16.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x7f41274db6d0> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x7f4111b9d120> False\n",
      "<keras.layers.pooling.max_pooling2d.MaxPooling2D object at 0x7f415c32b040> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x7f4111b9d3f0> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x7f41259fdd20> False\n",
      "<keras.layers.pooling.max_pooling2d.MaxPooling2D object at 0x7f413fd77730> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x7f41259fd840> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x7f41259fcb80> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x7f4125979b10> False\n",
      "<keras.layers.pooling.max_pooling2d.MaxPooling2D object at 0x7f41259d7cd0> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x7f41259a04f0> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x7f4111bd1720> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x7f4111bd2650> False\n",
      "<keras.layers.pooling.max_pooling2d.MaxPooling2D object at 0x7f41259ff310> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x7f4111bd1f00> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x7f4111bd1c30> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x7f4111bd3c10> False\n",
      "<keras.layers.pooling.max_pooling2d.MaxPooling2D object at 0x7f4111bd38b0> False\n",
      "<keras.layers.reshaping.flatten.Flatten object at 0x7f412597a200> True\n",
      "<keras.layers.core.dense.Dense object at 0x7f4111bed000> True\n",
      "<keras.layers.core.dense.Dense object at 0x7f4111bedb10> True\n",
      "<keras.layers.core.dense.Dense object at 0x7f4111bee290> True\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers:\n",
    "    print(layer, layer.trainable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = SGD(learning_rate=1e-4, momentum=0.9)\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=opt,metrics=[\"accuracy\"])\n",
    "es=EarlyStopping(monitor='val_accuracy', min_delta=0, patience=20, verbose=1, mode='auto')\n",
    "mc = ModelCheckpoint('/home/jszumny/Documents/copy of smoke data/hpwren/modeldata/best_model.h5', monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=True, mode='max', save_freq='epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_919672/1953829058.py:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  H = model.fit_generator(steps_per_epoch=50,generator=traindata, validation_data= testdata, validation_steps=10,epochs=100,callbacks=[mc,es])\n",
      "2023-06-05 15:43:06.218683: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.8525 - accuracy: 0.5967"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-05 15:46:30.655778: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_accuracy improved from -inf to 0.61667, saving model to /home/jszumny/Documents/copy of smoke data/hpwren/modeldata/best_model.h5\n",
      "50/50 [==============================] - 247s 5s/step - loss: 0.8525 - accuracy: 0.5967 - val_loss: 0.8262 - val_accuracy: 0.6167\n",
      "Epoch 2/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.7649 - accuracy: 0.6113\n",
      "Epoch 2: val_accuracy did not improve from 0.61667\n",
      "50/50 [==============================] - 247s 5s/step - loss: 0.7649 - accuracy: 0.6113 - val_loss: 0.7756 - val_accuracy: 0.6073\n",
      "Epoch 3/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.7279 - accuracy: 0.6198\n",
      "Epoch 3: val_accuracy did not improve from 0.61667\n",
      "50/50 [==============================] - 245s 5s/step - loss: 0.7279 - accuracy: 0.6198 - val_loss: 0.7327 - val_accuracy: 0.6156\n",
      "Epoch 4/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.7182 - accuracy: 0.6246\n",
      "Epoch 4: val_accuracy improved from 0.61667 to 0.62604, saving model to /home/jszumny/Documents/copy of smoke data/hpwren/modeldata/best_model.h5\n",
      "50/50 [==============================] - 245s 5s/step - loss: 0.7182 - accuracy: 0.6246 - val_loss: 0.7283 - val_accuracy: 0.6260\n",
      "Epoch 5/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.6994 - accuracy: 0.6319\n",
      "Epoch 5: val_accuracy did not improve from 0.62604\n",
      "50/50 [==============================] - 250s 5s/step - loss: 0.6994 - accuracy: 0.6319 - val_loss: 0.7096 - val_accuracy: 0.6125\n",
      "Epoch 6/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.6896 - accuracy: 0.6348\n",
      "Epoch 6: val_accuracy improved from 0.62604 to 0.64062, saving model to /home/jszumny/Documents/copy of smoke data/hpwren/modeldata/best_model.h5\n",
      "50/50 [==============================] - 236s 5s/step - loss: 0.6896 - accuracy: 0.6348 - val_loss: 0.6971 - val_accuracy: 0.6406\n",
      "Epoch 7/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.6829 - accuracy: 0.6348\n",
      "Epoch 7: val_accuracy improved from 0.64062 to 0.64167, saving model to /home/jszumny/Documents/copy of smoke data/hpwren/modeldata/best_model.h5\n",
      "50/50 [==============================] - 259s 5s/step - loss: 0.6829 - accuracy: 0.6348 - val_loss: 0.6909 - val_accuracy: 0.6417\n",
      "Epoch 8/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.6801 - accuracy: 0.6417\n",
      "Epoch 8: val_accuracy did not improve from 0.64167\n",
      "50/50 [==============================] - 201s 4s/step - loss: 0.6801 - accuracy: 0.6417 - val_loss: 0.6788 - val_accuracy: 0.6302\n",
      "Epoch 9/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.6718 - accuracy: 0.6385\n",
      "Epoch 9: val_accuracy improved from 0.64167 to 0.64688, saving model to /home/jszumny/Documents/copy of smoke data/hpwren/modeldata/best_model.h5\n",
      "50/50 [==============================] - 197s 4s/step - loss: 0.6718 - accuracy: 0.6385 - val_loss: 0.6852 - val_accuracy: 0.6469\n",
      "Epoch 10/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.6710 - accuracy: 0.6440\n",
      "Epoch 10: val_accuracy did not improve from 0.64688\n",
      "50/50 [==============================] - 202s 4s/step - loss: 0.6710 - accuracy: 0.6440 - val_loss: 0.6696 - val_accuracy: 0.6406\n",
      "Epoch 11/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.6664 - accuracy: 0.6446\n",
      "Epoch 11: val_accuracy did not improve from 0.64688\n",
      "50/50 [==============================] - 218s 4s/step - loss: 0.6664 - accuracy: 0.6446 - val_loss: 0.6723 - val_accuracy: 0.6417\n",
      "Epoch 12/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.6686 - accuracy: 0.6439\n",
      "Epoch 12: val_accuracy did not improve from 0.64688\n",
      "50/50 [==============================] - 237s 5s/step - loss: 0.6686 - accuracy: 0.6439 - val_loss: 0.6658 - val_accuracy: 0.6469\n",
      "Epoch 13/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.6613 - accuracy: 0.6525\n",
      "Epoch 13: val_accuracy improved from 0.64688 to 0.64896, saving model to /home/jszumny/Documents/copy of smoke data/hpwren/modeldata/best_model.h5\n",
      "50/50 [==============================] - 240s 5s/step - loss: 0.6613 - accuracy: 0.6525 - val_loss: 0.6605 - val_accuracy: 0.6490\n",
      "Epoch 14/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.6583 - accuracy: 0.6517\n",
      "Epoch 14: val_accuracy improved from 0.64896 to 0.65000, saving model to /home/jszumny/Documents/copy of smoke data/hpwren/modeldata/best_model.h5\n",
      "50/50 [==============================] - 274s 5s/step - loss: 0.6583 - accuracy: 0.6517 - val_loss: 0.6594 - val_accuracy: 0.6500\n",
      "Epoch 15/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.6590 - accuracy: 0.6531\n",
      "Epoch 15: val_accuracy did not improve from 0.65000\n",
      "50/50 [==============================] - 250s 5s/step - loss: 0.6590 - accuracy: 0.6531 - val_loss: 0.6680 - val_accuracy: 0.6458\n",
      "Epoch 16/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.6585 - accuracy: 0.6500\n",
      "Epoch 16: val_accuracy did not improve from 0.65000\n",
      "50/50 [==============================] - 233s 5s/step - loss: 0.6585 - accuracy: 0.6500 - val_loss: 0.6657 - val_accuracy: 0.6427\n",
      "Epoch 17/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.6577 - accuracy: 0.6540\n",
      "Epoch 17: val_accuracy improved from 0.65000 to 0.65104, saving model to /home/jszumny/Documents/copy of smoke data/hpwren/modeldata/best_model.h5\n",
      "50/50 [==============================] - 267s 5s/step - loss: 0.6577 - accuracy: 0.6540 - val_loss: 0.6663 - val_accuracy: 0.6510\n",
      "Epoch 18/100\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.6560 - accuracy: 0.6544\n",
      "Epoch 18: val_accuracy improved from 0.65104 to 0.65312, saving model to /home/jszumny/Documents/copy of smoke data/hpwren/modeldata/best_model.h5\n",
      "50/50 [==============================] - 241s 5s/step - loss: 0.6560 - accuracy: 0.6544 - val_loss: 0.6652 - val_accuracy: 0.6531\n",
      "Epoch 19/100\n",
      " 1/50 [..............................] - ETA: 3:54 - loss: 0.6493 - accuracy: 0.6667"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_919672/1953829058.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraindata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mtestdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2634\u001b[0m             \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2635\u001b[0m         )\n\u001b[0;32m-> 2636\u001b[0;31m         return self.fit(\n\u001b[0m\u001b[1;32m   2637\u001b[0m             \u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2638\u001b[0m             \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1683\u001b[0m                         ):\n\u001b[1;32m   1684\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1685\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1686\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1687\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 894\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    895\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    924\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 926\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    927\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    141\u001b[0m       (concrete_function,\n\u001b[1;32m    142\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m--> 143\u001b[0;31m     return concrete_function._call_flat(\n\u001b[0m\u001b[1;32m    144\u001b[0m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1755\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1756\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1757\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1758\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1759\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    379\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    382\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "H = model.fit_generator(steps_per_epoch=50,generator=traindata, validation_data= testdata, validation_steps=10,epochs=100,callbacks=[mc,es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
